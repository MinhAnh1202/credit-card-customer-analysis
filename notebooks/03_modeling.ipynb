{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d2b39b",
   "metadata": {},
   "source": [
    "# Logistic Regression Model - NumPy Implementation\n",
    "\n",
    "Notebook này triển khai mô hình **Logistic Regression** chỉ sử dụng **NumPy** để dự đoán **Customer Churn**. Chúng ta sẽ sử dụng dữ liệu đã được preprocessing từ notebook trước.\n",
    "\n",
    "## Mục tiêu:\n",
    "- Xây dựng Logistic Regression từ scratch chỉ với NumPy\n",
    "- Training và evaluation model trên dữ liệu thực tế\n",
    "- Trả lời các câu hỏi nhằm phân tích feature importance và model insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec7231",
   "metadata": {},
   "source": [
    "#### Môi trường code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9205c1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xv6/anaconda3/envs/min_ds-env/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4e9fa",
   "metadata": {},
   "source": [
    "## 1. Import Libraries và Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8ec427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import chỉ NumPy - không dùng thư viện nào khác!\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"/home/xv6/Lab 2/Credit Card Customer Analysis\")\n",
    "\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom Logistic Regression model\n",
    "import src.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379e4306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING PREPROCESSED DATA\n",
      "==================================================\n",
      "Data loaded thành công!\n",
      "Training set: (8102, 37)\n",
      "Test set: (2025, 37)\n",
      "Features: 37\n",
      "Class distribution - Train: Class 0: 6800, Class 1: 1302\n",
      "Class distribution - Test:  Class 0: 1700, Class 1: 325\n"
     ]
    }
   ],
   "source": [
    "# Load dữ liệu đã preprocessing\n",
    "data_dir = \"data/processed\"\n",
    "\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load training và test data\n",
    "X_train = np.load(f\"{data_dir}/X_train.npy\")\n",
    "y_train = np.load(f\"{data_dir}/y_train.npy\")\n",
    "X_test = np.load(f\"{data_dir}/X_test.npy\")\n",
    "y_test = np.load(f\"{data_dir}/y_test.npy\")\n",
    "\n",
    "# Load feature names\n",
    "with open(f\"{data_dir}/feature_names.txt\", \"r\") as f:\n",
    "    feature_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Data loaded thành công!\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Class distribution - Train: Class 0: {np.sum(y_train == 0)}, Class 1: {np.sum(y_train == 1)}\")\n",
    "print(f\"Class distribution - Test:  Class 0: {np.sum(y_test == 0)}, Class 1: {np.sum(y_test == 1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3391815",
   "metadata": {},
   "source": [
    "## 2. Khởi tạo và Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16c1275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION MODEL\n",
      "==================================================\n",
      "Learning rate: 0.01\n",
      "Max iterations: 1000\n",
      "Tolerance: 1e-06\n",
      "Fit intercept: True\n",
      "\n",
      "Bắt đầu training model...\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo Logistic Regression model\n",
    "model = models.LogisticRegression(\n",
    "    learning_rate=0.01,    # Tốc độ học\n",
    "    max_iter=1000,         # Số iterations tối đa\n",
    "    tolerance=1e-6,        # Tolerance để dừng khi converge\n",
    "    fit_intercept=True,    # Thêm bias term\n",
    "    verbose=True           # In quá trình training\n",
    ")\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Learning rate: {model.learning_rate}\")\n",
    "print(f\"Max iterations: {model.max_iter}\")\n",
    "print(f\"Tolerance: {model.tolerance}\")\n",
    "print(f\"Fit intercept: {model.fit_intercept}\")\n",
    "print(f\"\\nBắt đầu training model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06951b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BẮT ĐẦU TRAINING LOGISTIC REGRESSION\n",
      "   Features: 37\n",
      "   Samples: 8102\n",
      "   Learning rate: 0.01\n",
      "   Max iterations: 1000\n",
      "--------------------------------------------------\n",
      "   Iteration  100: Loss = 0.501711, Accuracy = 0.765\n",
      "   Iteration  200: Loss = 0.424545, Accuracy = 0.821\n",
      "   Iteration  300: Loss = 0.381359, Accuracy = 0.843\n",
      "   Iteration  400: Loss = 0.353228, Accuracy = 0.854\n",
      "   Iteration  500: Loss = 0.333206, Accuracy = 0.864\n",
      "   Iteration  600: Loss = 0.318160, Accuracy = 0.872\n",
      "   Iteration  700: Loss = 0.306422, Accuracy = 0.878\n",
      "   Iteration  800: Loss = 0.296997, Accuracy = 0.882\n",
      "   Iteration  900: Loss = 0.289253, Accuracy = 0.887\n",
      "   Iteration 1000: Loss = 0.282771, Accuracy = 0.888\n",
      "\n",
      " TRAINING HOÀN TẤT:\n",
      "   Final loss: 0.282771\n",
      "   Final accuracy: 0.888\n",
      "   Total iterations: 1000\n",
      "\n",
      "TRAINING SUMMARY:\n",
      "n_features: 37\n",
      "n_samples: 8102\n",
      "learning_rate: 0.010000\n",
      "max_iter: 1000\n",
      "actual_iter: 1000\n",
      "final_loss: 0.282771\n",
      "fit_intercept: True\n",
      "converged: False\n",
      "bias: -0.786739\n",
      "n_weights: 37\n",
      "\n",
      "Model đã được train thành công!\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nTRAINING SUMMARY:\")\n",
    "summary = model.get_model_summary()\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nModel đã được train thành công!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afc15d",
   "metadata": {},
   "source": [
    "## 3. Model Prediction và Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7077d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING PREDICTIONS\n",
      "==================================================\n",
      "Predictions hoàn tất!\n",
      "Train predictions: (8102,)\n",
      "Test predictions: (2025,)\n",
      "\n",
      "SAMPLE PREDICTIONS (10 test samples đầu tiên):\n",
      "True | Pred | Probability\n",
      "-------------------------\n",
      "  0  |  0  |   0.212\n",
      "  0  |  0  |   0.007\n",
      "  0  |  0  |   0.369\n",
      "  0  |  0  |   0.112\n",
      "  0  |  0  |   0.047\n",
      "  0  |  0  |   0.033\n",
      "  0  |  0  |   0.031\n",
      "  0  |  0  |   0.093\n",
      "  0  |  0  |   0.042\n",
      "  0  |  0  |   0.071\n",
      "\n",
      "PREDICTION DISTRIBUTION:\n",
      "Train - Class 0: 7,440, Class 1: 662\n",
      "Test  - Class 0: 1,876, Class 1: 149\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên training và test set\n",
    "print(\"MAKING PREDICTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training set predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]  # Probability for class 1\n",
    "\n",
    "# Test set predictions  \n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Predictions hoàn tất!\")\n",
    "print(f\"Train predictions: {y_train_pred.shape}\")\n",
    "print(f\"Test predictions: {y_test_pred.shape}\")\n",
    "\n",
    "# Quick preview of predictions\n",
    "print(f\"\\nSAMPLE PREDICTIONS (10 test samples đầu tiên):\")\n",
    "print(\"True | Pred | Probability\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(10):\n",
    "    print(f\"  {y_test[i]}  |  {y_test_pred[i]}  |   {y_test_proba[i]:.3f}\")\n",
    "    \n",
    "# Class distribution in predictions\n",
    "print(f\"\\nPREDICTION DISTRIBUTION:\")\n",
    "print(f\"Train - Class 0: {np.sum(y_train_pred == 0):,}, Class 1: {np.sum(y_train_pred == 1):,}\")\n",
    "print(f\"Test  - Class 0: {np.sum(y_test_pred == 0):,}, Class 1: {np.sum(y_test_pred == 1):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d68d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TRAINING SET PERFORMANCE:\n",
      "CLASSIFICATION REPORT\n",
      "==================================================\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                 Predicted\n",
      "                 Existing Customer Attrited Customer\n",
      "Actual Existing Customer      6667      133\n",
      "       Attrited Customer       773      529\n",
      "\n",
      "PERFORMANCE METRICS:\n",
      "Accuracy    : 0.8882\n",
      "Precision   : 0.7991\n",
      "Recall      : 0.4063\n",
      "F1-Score    : 0.5387\n",
      "Specificity : 0.9804\n",
      "AUC-ROC     : 0.8967\n"
     ]
    }
   ],
   "source": [
    "# Tính toán metrics cho training set\n",
    "train_metrics = models.calculate_classification_metrics(y_train, y_train_pred, y_train_proba)\n",
    "\n",
    "print(\" TRAINING SET PERFORMANCE:\")\n",
    "models.print_classification_report(train_metrics, class_names=['Existing Customer', 'Attrited Customer'])\n",
    "\n",
    "# Extract metrics for use in later cells\n",
    "train_accuracy = train_metrics['accuracy']\n",
    "train_precision = train_metrics['precision']\n",
    "train_recall = train_metrics['recall']\n",
    "train_f1 = train_metrics['f1_score']\n",
    "train_auc = train_metrics['auc_roc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab1e59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET PERFORMANCE:\n",
      "CLASSIFICATION REPORT\n",
      "==================================================\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                 Predicted\n",
      "                 Existing Customer Attrited Customer\n",
      "Actual Existing Customer      1673       27\n",
      "       Attrited Customer       203      122\n",
      "\n",
      "PERFORMANCE METRICS:\n",
      "Accuracy    : 0.8864\n",
      "Precision   : 0.8188\n",
      "Recall      : 0.3754\n",
      "F1-Score    : 0.5148\n",
      "Specificity : 0.9841\n",
      "AUC-ROC     : 0.8948\n"
     ]
    }
   ],
   "source": [
    "# Tính toán metrics cho test set\n",
    "test_metrics = models.calculate_classification_metrics(y_test, y_test_pred, y_test_proba)\n",
    "\n",
    "print(\"TEST SET PERFORMANCE:\")\n",
    "models.print_classification_report(test_metrics, class_names=['Existing Customer', 'Attrited Customer'])\n",
    "\n",
    "# Extract metrics for use in later cells\n",
    "test_accuracy = test_metrics['accuracy']\n",
    "test_precision = test_metrics['precision']\n",
    "test_recall = test_metrics['recall']\n",
    "test_f1 = test_metrics['f1_score']\n",
    "model_auc = test_metrics['auc_roc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529f958",
   "metadata": {},
   "source": [
    "## 4. Một số câu hỏi tìm hiểu về model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9294738",
   "metadata": {},
   "source": [
    "### Câu hỏi 1: Model có đang overfit hay underfit không? Việc này được đánh giá như thế nào?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25387028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CÂU HỎI 1: Model có đang overfit hay underfit không?\n",
      "============================================================\n",
      "\n",
      " PERFORMANCE COMPARISON:\n",
      "Training Accuracy: 0.8882\n",
      "Test Accuracy:     0.8864\n",
      "Accuracy Gap:      0.0018\n",
      "\n",
      "Training AUC:      0.8967\n",
      "Test AUC:          0.8948\n",
      "AUC Gap:           0.0019\n",
      "\n",
      " DIAGNOSIS:\n",
      " GOOD FIT: Model generalize tốt!\n",
      "   - Performance gaps nhỏ (< 5%)\n",
      "   - Test performance cao\n"
     ]
    }
   ],
   "source": [
    "# Câu hỏi 1: Đánh giá overfitting/underfitting\n",
    "print(\" CÂU HỎI 1: Model có đang overfit hay underfit không?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# So sánh performance train vs test\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "train_accuracy = np.mean(train_pred == y_train)\n",
    "test_accuracy = np.mean(test_pred == y_test)\n",
    "\n",
    "# Tính AUC cho train và test\n",
    "train_proba = model.predict_proba(X_train)\n",
    "test_proba = model.predict_proba(X_test)\n",
    "\n",
    "train_auc = models.calculate_auc_roc(y_train, train_proba[:, 1])\n",
    "test_auc = models.calculate_auc_roc(y_test, test_proba[:, 1])\n",
    "\n",
    "print(f\"\\n PERFORMANCE COMPARISON:\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Accuracy Gap:      {abs(train_accuracy - test_accuracy):.4f}\")\n",
    "\n",
    "print(f\"\\nTraining AUC:      {train_auc:.4f}\")\n",
    "print(f\"Test AUC:          {test_auc:.4f}\")\n",
    "print(f\"AUC Gap:           {abs(train_auc - test_auc):.4f}\")\n",
    "\n",
    "# Đánh giá\n",
    "accuracy_gap = abs(train_accuracy - test_accuracy)\n",
    "auc_gap = abs(train_auc - test_auc)\n",
    "\n",
    "print(f\"\\n DIAGNOSIS:\")\n",
    "if accuracy_gap < 0.05 and auc_gap < 0.05:\n",
    "    if test_accuracy > 0.8:\n",
    "        print(\" GOOD FIT: Model generalize tốt!\")\n",
    "        print(\"   - Performance gaps nhỏ (< 5%)\")\n",
    "        print(\"   - Test performance cao\")\n",
    "    else:\n",
    "        print(\"  UNDERFIT: Model còn đơn giản\")\n",
    "        print(\"   - Performance thấp cả train và test\")\n",
    "        print(\"   - Cần model phức tạp hơn hoặc thêm features\")\n",
    "elif accuracy_gap > 0.1 or auc_gap > 0.1:\n",
    "    print(\" OVERFIT: Model học thuộc training data\")\n",
    "    print(\"   - Train performance >> Test performance\")\n",
    "    print(\"   - Cần regularization hoặc giảm complexity\")\n",
    "else:\n",
    "    print(\" MILD OVERFIT: Hơi overfit nhẹ\")\n",
    "    print(\"   - Gap vừa phải (5-10%)\")\n",
    "    print(\"   - Có thể cần tune hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62bb010",
   "metadata": {},
   "source": [
    "### Câu hỏi 2: Features nào quan trọng nhất trong việc dự đoán churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b86f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CÂU HỎI 2: Features nào quan trọng nhất?\n",
      "==================================================\n",
      "\n",
      " TOP 10 FEATURES QUAN TRỌNG NHẤT:\n",
      "--------------------------------------------------\n",
      " 1. Total_Trans_Ct            │█████████████████████████████████████████│ 0.8264\n",
      " 2. Gender_M                  │████████████████████████████│ 0.5724\n",
      " 3. Total_Ct_Chng_Q4_Q1       │███████████████████████│ 0.4654\n",
      " 4. Gender_F                  │█████████████████████│ 0.4300\n",
      " 5. Marital_Status_Married    │████████████████████│ 0.4190\n",
      " 6. Card_Category_Blue        │██████████████████░░│ 0.3750\n",
      " 7. Total_Revolving_Bal       │██████████████████░░│ 0.3736\n",
      " 8. Education_Level_Post-Graduate │█████████████████░░░│ 0.3559\n",
      " 9. Total_Relationship_Count  │████████████████░░░░│ 0.3386\n",
      "10. Income_Category_$60K - $80K │███████████████░░░░░│ 0.3098\n",
      "\n",
      "  PHÂN TÍCH THEO NHÓM FEATURES:\n",
      "----------------------------------------\n",
      " Transaction Features: 3\n",
      "   - Total_Trans_Ct: 0.8264\n",
      "   - Total_Ct_Chng_Q4_Q1: 0.4654\n",
      "   - Total_Revolving_Bal: 0.3736\n",
      "\n",
      " Demographic Features: 5\n",
      "   - Gender_M: 0.5724\n",
      "   - Gender_F: 0.4300\n",
      "   - Marital_Status_Married: 0.4190\n",
      "   - Education_Level_Post-Graduate: 0.3559\n",
      "   - Income_Category_$60K - $80K: 0.3098\n",
      "\n",
      " Account Features: 2\n",
      "   - Card_Category_Blue: 0.3750\n",
      "   - Total_Relationship_Count: 0.3386\n"
     ]
    }
   ],
   "source": [
    "# Câu hỏi 2: Phân tích feature importance\n",
    "print(\" CÂU HỎI 2: Features nào quan trọng nhất?\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Lấy feature importance từ model weights\n",
    "feature_importance = model.get_feature_importance(feature_names)\n",
    "\n",
    "# Sắp xếp theo importance\n",
    "if isinstance(feature_importance, dict):\n",
    "    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    importance_values = [x[1] for x in sorted_features]\n",
    "    feature_names_sorted = [x[0] for x in sorted_features]\n",
    "else:\n",
    "    # Nếu return array thì tạo dictionary\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    importance_values = [x[1] for x in sorted_features]\n",
    "    feature_names_sorted = [x[0] for x in sorted_features]\n",
    "\n",
    "print(f\"\\n TOP 10 FEATURES QUAN TRỌNG NHẤT:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (feature, importance) in enumerate(sorted_features[:10], 1):\n",
    "    # Tạo bar chart đơn giản\n",
    "    bar_length = int(importance * 50)  # Scale to 50 chars max\n",
    "    bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
    "    print(f\"{i:2d}. {feature:<25} │{bar}│ {importance:.4f}\")\n",
    "\n",
    "# Phân tích nhóm features\n",
    "print(f\"\\n  PHÂN TÍCH THEO NHÓM FEATURES:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Phân loại features\n",
    "transaction_features = [f for f in feature_names_sorted[:10] if any(keyword in f.lower() \n",
    "                       for keyword in ['trans', 'amt', 'ct', 'revolving', 'utilization'])]\n",
    "demographic_features = [f for f in feature_names_sorted[:10] if any(keyword in f.lower() \n",
    "                       for keyword in ['age', 'gender', 'education', 'marital', 'income'])]\n",
    "account_features = [f for f in feature_names_sorted[:10] if any(keyword in f.lower() \n",
    "                   for keyword in ['credit', 'limit', 'card', 'months', 'relationship'])]\n",
    "\n",
    "print(f\" Transaction Features: {len(transaction_features)}\")\n",
    "if transaction_features:\n",
    "    for f in transaction_features:\n",
    "        idx = feature_names_sorted.index(f)\n",
    "        print(f\"   - {f}: {importance_values[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\n Demographic Features: {len(demographic_features)}\")\n",
    "if demographic_features:\n",
    "    for f in demographic_features:\n",
    "        idx = feature_names_sorted.index(f) \n",
    "        print(f\"   - {f}: {importance_values[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\n Account Features: {len(account_features)}\")\n",
    "if account_features:\n",
    "    for f in account_features:\n",
    "        idx = feature_names_sorted.index(f)\n",
    "        print(f\"   - {f}: {importance_values[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbadfc",
   "metadata": {},
   "source": [
    "### Câu hỏi 3: Model có stable không? - Sử dụng Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2d5ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CÂU HỎI 3: Cross-Validation - Model có stable không?\n",
      "============================================================\n",
      "Bắt đầu Cross-Validation với model hiện tại...\n",
      "Performing 5-Fold Cross Validation...\n",
      "Total samples: 10,127\n",
      "Samples per fold: ~2,025\n",
      "--------------------------------------------------\n",
      "Fold 1/5: Acc: 0.8894, AUC: 0.9105\n",
      "Fold 2/5: Acc: 0.9081, AUC: 0.9155\n",
      "Fold 3/5: Acc: 0.8983, AUC: 0.9094\n",
      "Fold 4/5: Acc: 0.9002, AUC: 0.9107\n",
      "Fold 5/5: Acc: 0.8821, AUC: 0.9074\n"
     ]
    }
   ],
   "source": [
    "# Câu hỏi 3: Cross-Validation để đánh giá model stability\n",
    "print(\" CÂU HỎI 3: Cross-Validation - Model có stable không?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Thực hiện Cross-Validation\n",
    "print(\"Bắt đầu Cross-Validation với model hiện tại...\")\n",
    "\n",
    "# Combine train và test để có full dataset\n",
    "X_full = np.vstack([X_train, X_test])\n",
    "y_full = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Model parameters giống như model đã train\n",
    "cv_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_iter': 1000,\n",
    "    'tolerance': 1e-6,\n",
    "    'fit_intercept': True,\n",
    "    'verbose': False  # Turn off verbose for CV\n",
    "}\n",
    "\n",
    "# Thực hiện 5-Fold CV sử dụng function từ models.py\n",
    "cv_scores, cv_details = models.kfold_cross_validation(\n",
    "    X_full, y_full, \n",
    "    models.LogisticRegression, \n",
    "    cv_model_params, \n",
    "    k=5, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aedf46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CROSS-VALIDATION RESULTS:\n",
      "==================================================\n",
      "ACCURACY  : 0.8956 ± 0.0090\n",
      "Range     : [0.8821, 0.9081]\n",
      "-------------------------\n",
      "PRECISION : 0.8372 ± 0.0213\n",
      "Range     : [0.8148, 0.8773]\n",
      "-------------------------\n",
      "RECALL    : 0.4358 ± 0.0394\n",
      "Range     : [0.3862, 0.4955]\n",
      "-------------------------\n",
      "F1        : 0.5722 ± 0.0357\n",
      "Range     : [0.5286, 0.6203]\n",
      "-------------------------\n",
      "AUC       : 0.9107 ± 0.0027\n",
      "Range     : [0.9074, 0.9155]\n",
      "-------------------------\n",
      "\n",
      " DETAILED FOLD ANALYSIS:\n",
      "------------------------------------------------------------\n",
      "Fold   │ Accuracy   │ Precision  │ Recall     │ F1         │ AUC       \n",
      "------------------------------------------------------------\n",
      "1      │ 0.8894     │ 0.8148     │ 0.4049     │ 0.5410     │ 0.9105    \n",
      "2      │ 0.9081     │ 0.8773     │ 0.4628     │ 0.6059     │ 0.9155    \n",
      "3      │ 0.8983     │ 0.8272     │ 0.4295     │ 0.5654     │ 0.9094    \n",
      "4      │ 0.9002     │ 0.8291     │ 0.4955     │ 0.6203     │ 0.9107    \n",
      "5      │ 0.8821     │ 0.8375     │ 0.3862     │ 0.5286     │ 0.9074    \n",
      "------------------------------------------------------------\n",
      "Mean   │ 0.8956     │ 0.8372     │ 0.4358     │ 0.5722     │ 0.9107    \n",
      "Std    │ 0.0090     │ 0.0213     │ 0.0394     │ 0.0357     │ 0.0027    \n",
      "\n",
      " STABILITY ANALYSIS:\n",
      "========================================\n",
      "COEFFICIENT OF VARIATION (Lower = More Stable):\n",
      "  accuracy  : 0.0101 (EXCELLENT)\n",
      "  precision : 0.0255 (EXCELLENT)\n",
      "  recall    : 0.0903 (GOOD)\n",
      "  f1        : 0.0624 (GOOD)\n",
      "  auc       : 0.0029 (EXCELLENT)\n",
      "\n",
      " Overall Stability: EXCELLENT - Model rất stable\n",
      "\n",
      " COMPARISON: Cross-Validation vs Single Split\n",
      "--------------------------------------------------\n",
      "Metric       │ CV Mean    │ CV Std     │ Single Split │ Difference\n",
      "--------------------------------------------------\n",
      "accuracy     │ 0.8956     │ 0.0090     │ 0.8864       │ 0.0092    \n",
      "precision    │ 0.8372     │ 0.0213     │ 0.8188       │ 0.0184    \n",
      "recall       │ 0.4358     │ 0.0394     │ 0.3754       │ 0.0604    \n",
      "f1           │ 0.5722     │ 0.0357     │ 0.5148       │ 0.0575    \n",
      "auc          │ 0.9107     │ 0.0027     │ 0.8948       │ 0.0159    \n",
      "\n",
      " 95% CONFIDENCE INTERVALS:\n",
      "-----------------------------------\n",
      "accuracy  : [0.8877, 0.9035]\n",
      "precision : [0.8185, 0.8559]\n",
      "recall    : [0.4013, 0.4703]\n",
      "f1        : [0.5409, 0.6035]\n",
      "auc       : [0.9084, 0.9130]\n",
      "\n",
      " BUSINESS IMPLICATIONS:\n",
      "-------------------------\n",
      " Average Performance: 89.6% accuracy\n",
      " Performance Variability: ±0.9%\n",
      " LOW VARIANCE - Reliable for production deployment\n"
     ]
    }
   ],
   "source": [
    "# Phân tích stability và interpretation sử dụng functions từ models.py\n",
    "single_split_metrics = {\n",
    "    'accuracy': test_accuracy,\n",
    "    'precision': test_precision, \n",
    "    'recall': test_recall,\n",
    "    'f1': test_f1,\n",
    "    'auc': model_auc\n",
    "}\n",
    "\n",
    "# In kết quả cross-validation với comparison\n",
    "models.print_cv_results(cv_scores, cv_details, single_split_metrics)\n",
    "\n",
    "# Thêm phân tích chi tiết\n",
    "analysis_results = models.analyze_cv_stability(cv_scores, single_split_metrics)\n",
    "\n",
    "print(f\"\\n 95% CONFIDENCE INTERVALS:\")\n",
    "print(\"-\" * 35)\n",
    "for metric_name, summary in analysis_results['metrics_summary'].items():\n",
    "    mean = summary['mean']\n",
    "    std = summary['std']\n",
    "    # 95% CI = mean ± 1.96 * std/sqrt(n)\n",
    "    margin_error = 1.96 * std / np.sqrt(5)  # n=5 folds\n",
    "    ci_lower = mean - margin_error\n",
    "    ci_upper = mean + margin_error\n",
    "    print(f\"{metric_name:<10}: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "print(f\"\\n BUSINESS IMPLICATIONS:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "metrics_summary = analysis_results['metrics_summary']\n",
    "avg_cv = analysis_results['avg_cv']\n",
    "\n",
    "print(f\" Average Performance: {metrics_summary['accuracy']['mean']:.1%} accuracy\")\n",
    "print(f\" Performance Variability: ±{metrics_summary['accuracy']['std']*100:.1f}%\")\n",
    "\n",
    "# Business implications\n",
    "if metrics_summary['accuracy']['std'] < 0.02:\n",
    "    print(f\" LOW VARIANCE - Reliable for production deployment\")\n",
    "elif metrics_summary['accuracy']['std'] < 0.05:\n",
    "    print(f\"  MODERATE VARIANCE - Monitor performance closely\")\n",
    "else:\n",
    "    print(f\" HIGH VARIANCE - Consider more data or model tuning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

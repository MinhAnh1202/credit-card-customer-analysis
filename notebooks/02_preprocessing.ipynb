{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affa3f6b",
   "metadata": {},
   "source": [
    "# Data Preprocessing cho Logistic Regression\n",
    "\n",
    "Notebook n√†y ch·ª©a c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ƒë·ªÉ chu·∫©n b·ªã cho m√¥ h√¨nh Logistic Regression d·ª± ƒëo√°n Customer Churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5416c9f",
   "metadata": {},
   "source": [
    "#### M√¥i tr∆∞·ªùng code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2f3bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xv6/anaconda3/envs/min_ds-env/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814792db",
   "metadata": {},
   "source": [
    "#### Import th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0af7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"/home/xv6/Lab 2/Credit Card Customer Analysis\")\n",
    "\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "import src.data_processing as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c16261",
   "metadata": {},
   "source": [
    "## 1. Load d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9224b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë d√≤ng: 10127\n",
      "S·ªë c·ªôt: 21\n"
     ]
    }
   ],
   "source": [
    "# Load d·ªØ li·ªáu\n",
    "data_path = \"data/raw/BankChurners.csv\"\n",
    "data = dp.load_data(data_path)\n",
    "\n",
    "# Preprocessing b∆∞·ªõc ƒë·∫ßu: lo·∫°i b·ªè 2 c·ªôt cu·ªëi nh∆∞ ƒë√£ ph√¢n t√≠ch\n",
    "data_clean = dp.preprocess_data(data, exclude_last_n=2)\n",
    "\n",
    "print(f\"S·ªë d√≤ng: {data_clean.shape[0]}\")\n",
    "print(f\"S·ªë c·ªôt: {len(data_clean.dtype.names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572cb3eb",
   "metadata": {},
   "source": [
    "## 2. T·∫°o target variable cho Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cec24ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ph√¢n b·ªë target:\n",
      "Existing Customer (class 0): 8,500 (83.9%)\n",
      "Attrited Customer (class 1): 1,627 (16.1%)\n"
     ]
    }
   ],
   "source": [
    "# S·ª≠ d·ª•ng h√†m t·∫°o target binary t·ª´ module\n",
    "target_binary = dp.create_binary_target(data_clean, 'Attrition_Flag', 'Attrited Customer')\n",
    "\n",
    "print(\"Ph√¢n b·ªë target:\")\n",
    "unique, counts = np.unique(target_binary, return_counts=True)\n",
    "for val, count in zip(unique, counts):\n",
    "    label = \"Attrited Customer\" if val == 1 else \"Existing Customer\"\n",
    "    percentage = count / len(target_binary) * 100\n",
    "    print(f\"{label} (class {val}): {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc0ace",
   "metadata": {},
   "source": [
    "## 3. Feature Selection v√† Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579c6691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√°c features s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng:\n",
      "==================================================\n",
      "NUMERIC FEATURES:\n",
      " 1. Customer_Age\n",
      " 2. Dependent_count\n",
      " 3. Months_on_book\n",
      " 4. Total_Relationship_Count\n",
      " 5. Months_Inactive_12_mon\n",
      " 6. Contacts_Count_12_mon\n",
      " 7. Credit_Limit\n",
      " 8. Total_Revolving_Bal\n",
      " 9. Avg_Open_To_Buy\n",
      "10. Total_Amt_Chng_Q4_Q1\n",
      "11. Total_Trans_Amt\n",
      "12. Total_Trans_Ct\n",
      "13. Total_Ct_Chng_Q4_Q1\n",
      "14. Avg_Utilization_Ratio\n",
      "\n",
      "CATEGORICAL FEATURES:\n",
      " 1. Gender\n",
      " 2. Education_Level\n",
      " 3. Marital_Status\n",
      " 4. Income_Category\n",
      " 5. Card_Category\n",
      "\n",
      "T·ªîNG K·∫æT:\n",
      "- T·ªïng s·ªë features: 19\n",
      "- Numeric features: 14\n",
      "- Categorical features: 5\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection s·ª≠ d·ª•ng c√°c h√†m c√≥ s·∫µn t·ª´ module\n",
    "excluded_columns = ['CLIENTNUM', 'Attrition_Flag']  # ID v√† target\n",
    "\n",
    "# S·ª≠ d·ª•ng h√†m get_numeric_columns v√† get_categorical_columns t·ª´ module\n",
    "numeric_features = dp.get_numeric_columns(data_clean, exclude_columns=excluded_columns)\n",
    "\n",
    "categorical_features = dp.get_categorical_columns(data_clean)\n",
    "categorical_features = [col for col in categorical_features if col not in excluded_columns]\n",
    "\n",
    "# T·ªïng h·ª£p feature columns\n",
    "feature_columns = numeric_features + categorical_features\n",
    "\n",
    "print(\"C√°c features s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"NUMERIC FEATURES:\")\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nCATEGORICAL FEATURES:\")\n",
    "for i, col in enumerate(categorical_features, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nT·ªîNG K·∫æT:\")\n",
    "print(f\"- T·ªïng s·ªë features: {len(feature_columns)}\")\n",
    "print(f\"- Numeric features: {len(numeric_features)}\")\n",
    "print(f\"- Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539e104",
   "metadata": {},
   "source": [
    "### 3.1 Ki·ªÉm tra Missing Values v√† Unknown Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc898ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU\n",
      "============================================================\n",
      "\n",
      "NUMERIC FEATURES - Missing Values:\n",
      "----------------------------------------\n",
      "Customer_Age: Kh√¥ng c√≥ missing values\n",
      "Dependent_count: Kh√¥ng c√≥ missing values\n",
      "Months_on_book: Kh√¥ng c√≥ missing values\n",
      "Total_Relationship_Count: Kh√¥ng c√≥ missing values\n",
      "Months_Inactive_12_mon: Kh√¥ng c√≥ missing values\n",
      "Contacts_Count_12_mon: Kh√¥ng c√≥ missing values\n",
      "Credit_Limit: Kh√¥ng c√≥ missing values\n",
      "Total_Revolving_Bal: Kh√¥ng c√≥ missing values\n",
      "Avg_Open_To_Buy: Kh√¥ng c√≥ missing values\n",
      "Total_Amt_Chng_Q4_Q1: Kh√¥ng c√≥ missing values\n",
      "Total_Trans_Amt: Kh√¥ng c√≥ missing values\n",
      "Total_Trans_Ct: Kh√¥ng c√≥ missing values\n",
      "Total_Ct_Chng_Q4_Q1: Kh√¥ng c√≥ missing values\n",
      "Avg_Utilization_Ratio: Kh√¥ng c√≥ missing values\n",
      "T·∫•t c·∫£ numeric features ƒë·ªÅu kh√¥ng c√≥ missing values!\n",
      "\n",
      "CATEGORICAL FEATURES - Unknown/Missing Values:\n",
      "--------------------------------------------------\n",
      "\n",
      "Gender:\n",
      "  Unique values: 2\n",
      "  Values: ['F', 'M']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Education_Level:\n",
      "  Unique values: 7\n",
      "  Values: ['College', 'Doctorate', 'Graduate', 'High School', 'Post-Graduate', 'Uneducated', 'Unknown']\n",
      "  Missing/Unknown: 1519 (15.00%)\n",
      "\n",
      "Marital_Status:\n",
      "  Unique values: 4\n",
      "  Values: ['Divorced', 'Married', 'Single', 'Unknown']\n",
      "  Missing/Unknown: 749 (7.40%)\n",
      "\n",
      "Income_Category:\n",
      "  Unique values: 6\n",
      "  Values: ['$120K +', '$40K - $60K', '$60K - $80K', '$80K - $120K', 'Less than $40K', 'Unknown']\n",
      "  Missing/Unknown: 1112 (10.98%)\n",
      "\n",
      "Card_Category:\n",
      "  Unique values: 4\n",
      "  Values: ['Blue', 'Gold', 'Platinum', 'Silver']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "T·ªîNG K·∫æT CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU:\n",
      "----------------------------------------\n",
      "T·ªïng s·ªë samples: 10,127\n",
      "Numeric features c√≥ v·∫•n ƒë·ªÅ: 0/14\n",
      "Categorical features c√≥ v·∫•n ƒë·ªÅ: 3/5\n",
      "T·ªïng features c√≥ v·∫•n ƒë·ªÅ: 3/19\n",
      "\n",
      "C√ÅC V·∫§N ƒê·ªÄ PH√ÅT HI·ªÜN:\n",
      "- Education_Level (categorical): 1519 missing values (15.00%)\n",
      "- Marital_Status (categorical): 749 missing values (7.40%)\n",
      "- Income_Category (categorical): 1112 missing values (10.98%)\n"
     ]
    }
   ],
   "source": [
    "# S·ª≠ d·ª•ng h√†m ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu t·ª´ module\n",
    "quality_issues = dp.check_data_quality_detailed(data_clean, numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6495b55",
   "metadata": {},
   "source": [
    "### 3.2 X·ª≠ l√Ω Missing Values cho Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1fb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ X·ª¨ L√ù MISSING VALUES\n",
      "============================================================\n",
      "\n",
      "Gender:\n",
      "  Missing before: 0\n",
      "  Missing after: 0\n",
      "  Ho√†n th√†nh x·ª≠ l√Ω missing values cho c·ªôt Gender.\n",
      "\n",
      "Education_Level:\n",
      "  Missing before: 1519\n",
      "  Missing after: 0\n",
      "  Ho√†n th√†nh x·ª≠ l√Ω missing values cho c·ªôt Education_Level.\n",
      "\n",
      "Marital_Status:\n",
      "  Missing before: 749\n",
      "  Missing after: 0\n",
      "  Ho√†n th√†nh x·ª≠ l√Ω missing values cho c·ªôt Marital_Status.\n",
      "\n",
      "Income_Category:\n",
      "  Missing before: 1112\n",
      "  Missing after: 0\n",
      "  Ho√†n th√†nh x·ª≠ l√Ω missing values cho c·ªôt Income_Category.\n",
      "\n",
      "Card_Category:\n",
      "  Missing before: 0\n",
      "  Missing after: 0\n",
      "  Ho√†n th√†nh x·ª≠ l√Ω missing values cho c·ªôt Card_Category.\n"
     ]
    }
   ],
   "source": [
    "# Th·ª±c hi·ªán x·ª≠ l√Ω missing values\n",
    "data_processed = data_clean[feature_columns]\n",
    "data_with_handled_missing, imputation_info = dp.handle_categorical_missing_values(data_processed)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"K·∫æT QU·∫¢ X·ª¨ L√ù MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col, info in imputation_info.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Missing before: {info['missing_count_before']}\")\n",
    "    print(f\"  Missing after: {info['missing_count_after']}\")\n",
    "    print(f\"  Ho√†n th√†nh x·ª≠ l√Ω missing values cho c·ªôt {col}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c3d89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " KI·ªÇM TRA L·∫†I SAU KHI X·ª¨ L√ù MISSING VALUES\n",
      "============================================================\n",
      "KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU\n",
      "============================================================\n",
      "\n",
      "NUMERIC FEATURES - Missing Values:\n",
      "----------------------------------------\n",
      "Customer_Age: Kh√¥ng c√≥ missing values\n",
      "Dependent_count: Kh√¥ng c√≥ missing values\n",
      "Months_on_book: Kh√¥ng c√≥ missing values\n",
      "Total_Relationship_Count: Kh√¥ng c√≥ missing values\n",
      "Months_Inactive_12_mon: Kh√¥ng c√≥ missing values\n",
      "Contacts_Count_12_mon: Kh√¥ng c√≥ missing values\n",
      "Credit_Limit: Kh√¥ng c√≥ missing values\n",
      "Total_Revolving_Bal: Kh√¥ng c√≥ missing values\n",
      "Avg_Open_To_Buy: Kh√¥ng c√≥ missing values\n",
      "Total_Amt_Chng_Q4_Q1: Kh√¥ng c√≥ missing values\n",
      "Total_Trans_Amt: Kh√¥ng c√≥ missing values\n",
      "Total_Trans_Ct: Kh√¥ng c√≥ missing values\n",
      "Total_Ct_Chng_Q4_Q1: Kh√¥ng c√≥ missing values\n",
      "Avg_Utilization_Ratio: Kh√¥ng c√≥ missing values\n",
      "T·∫•t c·∫£ numeric features ƒë·ªÅu kh√¥ng c√≥ missing values!\n",
      "\n",
      "CATEGORICAL FEATURES - Unknown/Missing Values:\n",
      "--------------------------------------------------\n",
      "\n",
      "Gender:\n",
      "  Unique values: 2\n",
      "  Values: ['F', 'M']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Education_Level:\n",
      "  Unique values: 6\n",
      "  Values: ['College', 'Doctorate', 'Graduate', 'High School', 'Post-Graduate', 'Uneducated']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Marital_Status:\n",
      "  Unique values: 3\n",
      "  Values: ['Divorced', 'Married', 'Single']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Income_Category:\n",
      "  Unique values: 5\n",
      "  Values: ['$120K +', '$40K - $60K', '$60K - $80K', '$80K - $120K', 'Less than $40K']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Card_Category:\n",
      "  Unique values: 4\n",
      "  Values: ['Blue', 'Gold', 'Platinum', 'Silver']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "üéâ T·∫•t c·∫£ categorical features ƒë·ªÅu kh√¥ng c√≥ missing/unknown values!\n",
      "\n",
      "T·ªîNG K·∫æT CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU:\n",
      "----------------------------------------\n",
      "T·ªïng s·ªë samples: 10,127\n",
      "Numeric features c√≥ v·∫•n ƒë·ªÅ: 0/14\n",
      "Categorical features c√≥ v·∫•n ƒë·ªÅ: 0/5\n",
      "T·ªïng features c√≥ v·∫•n ƒë·ªÅ: 0/19\n",
      "\n",
      " KH√îNG C√ì V·∫§N ƒê·ªÄ V·ªÄ CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU!\n",
      "\n",
      "SO S√ÅNH TR∆Ø·ªöC V√Ä SAU X·ª¨ L√ù:\n",
      "----------------------------------------\n",
      "Features c√≥ missing values tr∆∞·ªõc: 3\n",
      "Features c√≥ missing values sau: 0\n",
      "ƒê√É X·ª¨ L√ù TH√ÄNH C√îNG T·∫§T C·∫¢ MISSING VALUES!\n",
      "Dependent_count: Kh√¥ng c√≥ missing values\n",
      "Months_on_book: Kh√¥ng c√≥ missing values\n",
      "Total_Relationship_Count: Kh√¥ng c√≥ missing values\n",
      "Months_Inactive_12_mon: Kh√¥ng c√≥ missing values\n",
      "Contacts_Count_12_mon: Kh√¥ng c√≥ missing values\n",
      "Credit_Limit: Kh√¥ng c√≥ missing values\n",
      "Total_Revolving_Bal: Kh√¥ng c√≥ missing values\n",
      "Avg_Open_To_Buy: Kh√¥ng c√≥ missing values\n",
      "Total_Amt_Chng_Q4_Q1: Kh√¥ng c√≥ missing values\n",
      "Total_Trans_Amt: Kh√¥ng c√≥ missing values\n",
      "Total_Trans_Ct: Kh√¥ng c√≥ missing values\n",
      "Total_Ct_Chng_Q4_Q1: Kh√¥ng c√≥ missing values\n",
      "Avg_Utilization_Ratio: Kh√¥ng c√≥ missing values\n",
      "T·∫•t c·∫£ numeric features ƒë·ªÅu kh√¥ng c√≥ missing values!\n",
      "\n",
      "CATEGORICAL FEATURES - Unknown/Missing Values:\n",
      "--------------------------------------------------\n",
      "\n",
      "Gender:\n",
      "  Unique values: 2\n",
      "  Values: ['F', 'M']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Education_Level:\n",
      "  Unique values: 6\n",
      "  Values: ['College', 'Doctorate', 'Graduate', 'High School', 'Post-Graduate', 'Uneducated']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Marital_Status:\n",
      "  Unique values: 3\n",
      "  Values: ['Divorced', 'Married', 'Single']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Income_Category:\n",
      "  Unique values: 5\n",
      "  Values: ['$120K +', '$40K - $60K', '$60K - $80K', '$80K - $120K', 'Less than $40K']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "Card_Category:\n",
      "  Unique values: 4\n",
      "  Values: ['Blue', 'Gold', 'Platinum', 'Silver']\n",
      "  Kh√¥ng c√≥ missing/unknown values\n",
      "\n",
      "üéâ T·∫•t c·∫£ categorical features ƒë·ªÅu kh√¥ng c√≥ missing/unknown values!\n",
      "\n",
      "T·ªîNG K·∫æT CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU:\n",
      "----------------------------------------\n",
      "T·ªïng s·ªë samples: 10,127\n",
      "Numeric features c√≥ v·∫•n ƒë·ªÅ: 0/14\n",
      "Categorical features c√≥ v·∫•n ƒë·ªÅ: 0/5\n",
      "T·ªïng features c√≥ v·∫•n ƒë·ªÅ: 0/19\n",
      "\n",
      " KH√îNG C√ì V·∫§N ƒê·ªÄ V·ªÄ CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU!\n",
      "\n",
      "SO S√ÅNH TR∆Ø·ªöC V√Ä SAU X·ª¨ L√ù:\n",
      "----------------------------------------\n",
      "Features c√≥ missing values tr∆∞·ªõc: 3\n",
      "Features c√≥ missing values sau: 0\n",
      "ƒê√É X·ª¨ L√ù TH√ÄNH C√îNG T·∫§T C·∫¢ MISSING VALUES!\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra k·∫øt qu·∫£ sau khi x·ª≠ l√Ω missing values\n",
    "print(\"\\n\" + \" KI·ªÇM TRA L·∫†I SAU KHI X·ª¨ L√ù MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# S·ª≠ d·ª•ng l·∫°i h√†m check_data_quality_detailed ƒë·ªÉ ki·ªÉm tra\n",
    "quality_issues_after = dp.check_data_quality_detailed(\n",
    "    data_with_handled_missing, numeric_features, categorical_features\n",
    ")\n",
    "\n",
    "print(f\"\\nSO S√ÅNH TR∆Ø·ªöC V√Ä SAU X·ª¨ L√ù:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Features c√≥ missing values tr∆∞·ªõc: {len(quality_issues)}\")\n",
    "print(f\"Features c√≥ missing values sau: {len(quality_issues_after)}\")\n",
    "\n",
    "if len(quality_issues_after) == 0:\n",
    "    print(\"ƒê√É X·ª¨ L√ù TH√ÄNH C√îNG T·∫§T C·∫¢ MISSING VALUES!\")\n",
    "else:\n",
    "    print(\"V·∫´n c√≤n m·ªôt s·ªë missing values:\")\n",
    "    for issue in quality_issues_after:\n",
    "        print(f\" {issue['column']}: {issue['missing_count']} missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72be9978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU CHO PREPROCESSING\n",
      "==================================================\n",
      "ƒê√£ c·∫≠p nh·∫≠t data_clean v·ªõi d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω missing values\n"
     ]
    }
   ],
   "source": [
    "# C·∫≠p nh·∫≠t d·ªØ li·ªáu cho preprocessing ti·∫øp theo\n",
    "print(\"C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU CHO PREPROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Thay th·∫ø data_clean b·∫±ng data ƒë√£ x·ª≠ l√Ω missing values\n",
    "data_clean = data_with_handled_missing\n",
    "print(\"ƒê√£ c·∫≠p nh·∫≠t data_clean v·ªõi d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4fdf6",
   "metadata": {},
   "source": [
    "### 3.4 Feature Engineering - T·∫°o Features M·ªõi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bc2f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ENGINEERING\n",
      "============================================================\n",
      "D·ªØ li·ªáu hi·ªán t·∫°i: 19 columns\n",
      "\n",
      "T·∫†O 4 NUMERIC FEATURES M·ªöI:\n",
      "1. Credit_Utilization_Efficiency: min = 1.00, max = 34516.00, mean = 1965.92\n",
      "2. Customer_Activity_Score: min = 98.15, max = 143891.00, mean = 10109.92\n",
      "3. Avg_Transaction_Amount: min = 19.14, max =  190.19, mean = 62.61\n",
      "\n",
      "ƒê√£ t·∫°o 3 features s·ªë m·ªõi!\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - T·∫°o 4 features s·ªë (kh√¥ng c√≥ categorical)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# T·∫°o copy ƒë·ªÉ th√™m features m·ªõi\n",
    "data_with_features = data_clean.copy()\n",
    "print(f\"D·ªØ li·ªáu hi·ªán t·∫°i: {len(data_clean.dtype.names)} columns\")\n",
    "\n",
    "# ===== 4 FEATURES S·ªê =====\n",
    "print(\"\\nT·∫†O 4 NUMERIC FEATURES M·ªöI:\")\n",
    "\n",
    "# 1. Credit Utilization Efficiency (Hi·ªáu qu·∫£ s·ª≠ d·ª•ng credit)\n",
    "# = Credit_Limit / (Total_Revolving_Bal + 1) ƒë·ªÉ tr√°nh chia cho 0\n",
    "credit_utilization_efficiency = data_clean['Credit_Limit'] / (data_clean['Total_Revolving_Bal'] + 1)\n",
    "\n",
    "# 2. Customer Activity Score (ƒêi·ªÉm ho·∫°t ƒë·ªông kh√°ch h√†ng)\n",
    "# = (Total_Trans_Ct * Total_Trans_Amt) / (Months_on_book + 1)\n",
    "customer_activity_score = (data_clean['Total_Trans_Ct'] * data_clean['Total_Trans_Amt']) / (data_clean['Months_on_book'] + 1)\n",
    "\n",
    "# 3. Average Transaction Amount \n",
    "# = Total_Trans_Amt / Total_Trans_Ct\n",
    "avg_transaction_amount = data_clean['Total_Trans_Amt'] / np.maximum(data_clean['Total_Trans_Ct'], 1)\n",
    "\n",
    "print(f\"1. Credit_Utilization_Efficiency: min = {np.min(credit_utilization_efficiency):.2f}, max = {np.max(credit_utilization_efficiency):.2f}, mean = {np.mean(credit_utilization_efficiency):.2f}\")\n",
    "print(f\"2. Customer_Activity_Score: min = {np.min(customer_activity_score):.2f}, max = {np.max(customer_activity_score):.2f}, mean = {np.mean(customer_activity_score):.2f}\")\n",
    "print(f\"3. Avg_Transaction_Amount: min = {np.min(avg_transaction_amount):.2f}, max =  {np.max(avg_transaction_amount):.2f}, mean = {np.mean(avg_transaction_amount):.2f}\")\n",
    "\n",
    "print(f\"\\nƒê√£ t·∫°o 3 features s·ªë m·ªõi!\")\n",
    "\n",
    "# L∆∞u features ƒë·ªÉ s·ª≠ d·ª•ng sau\n",
    "engineered_numeric_features = {\n",
    "    'Credit_Utilization_Efficiency': credit_utilization_efficiency,\n",
    "    'Customer_Activity_Score': customer_activity_score,\n",
    "    'Avg_Transaction_Amount': avg_transaction_amount\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012c5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TH√äM FEATURES M·ªöI V√ÄO STRUCTURED ARRAY\n",
      "==================================================\n",
      "C√°c fields m·ªõi ƒë∆∞·ª£c th√™m:\n",
      "  - Credit_Utilization_Efficiency (f8)\n",
      "  - Customer_Activity_Score (f8)\n",
      "  - Avg_Transaction_Amount (f8)\n",
      "\n",
      "K·∫æT QU·∫¢:\n",
      "Columns tr∆∞·ªõc feature engineering: 19\n",
      "Columns sau feature engineering: 22\n",
      "S·ªë features m·ªõi: 3\n",
      "\n",
      "Danh s√°ch t·∫•t c·∫£ columns hi·ªán t·∫°i:\n",
      " 1.     Customer_Age\n",
      " 2.     Dependent_count\n",
      " 3.     Months_on_book\n",
      " 4.     Total_Relationship_Count\n",
      " 5.     Months_Inactive_12_mon\n",
      " 6.     Contacts_Count_12_mon\n",
      " 7.     Credit_Limit\n",
      " 8.     Total_Revolving_Bal\n",
      " 9.     Avg_Open_To_Buy\n",
      "10.     Total_Amt_Chng_Q4_Q1\n",
      "11.     Total_Trans_Amt\n",
      "12.     Total_Trans_Ct\n",
      "13.     Total_Ct_Chng_Q4_Q1\n",
      "14.     Avg_Utilization_Ratio\n",
      "15.     Gender\n",
      "16.     Education_Level\n",
      "17.     Marital_Status\n",
      "18.     Income_Category\n",
      "19.     Card_Category\n",
      "20. NEW Credit_Utilization_Efficiency\n",
      "21. NEW Customer_Activity_Score\n",
      "22. NEW Avg_Transaction_Amount\n",
      "\n",
      " ƒê√£ c·∫≠p nh·∫≠t data_clean v·ªõi 3 features s·ªë m·ªõi th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o structured array v·ªõi features m·ªõi\n",
    "print(\"TH√äM FEATURES M·ªöI V√ÄO STRUCTURED ARRAY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# T·∫°o dtype m·ªõi t·ª´ ƒë·∫ßu thay v√¨ modify dtype c≈©\n",
    "original_names = list(data_clean.dtype.names)\n",
    "original_dtypes = [data_clean.dtype[name] for name in original_names]\n",
    "\n",
    "# T·∫°o list dtype m·ªõi\n",
    "new_dtype_list = []\n",
    "for name, dtype in zip(original_names, original_dtypes):\n",
    "    new_dtype_list.append((name, dtype))\n",
    "\n",
    "# Th√™m 3 features m·ªõi\n",
    "new_fields = [\n",
    "    ('Credit_Utilization_Efficiency', 'f8'),  # float64\n",
    "    ('Customer_Activity_Score', 'f8'),         # float64  \n",
    "    ('Avg_Transaction_Amount', 'f8'),          # float64\n",
    "]\n",
    "\n",
    "new_dtype_list.extend(new_fields)\n",
    "\n",
    "print(f\"C√°c fields m·ªõi ƒë∆∞·ª£c th√™m:\")\n",
    "for field_name, field_type in new_fields:\n",
    "    print(f\"  - {field_name} ({field_type})\")\n",
    "\n",
    "# T·∫°o array m·ªõi v·ªõi dtype m·ªü r·ªông\n",
    "data_enhanced = np.zeros(len(data_clean), dtype=new_dtype_list)\n",
    "\n",
    "# Copy d·ªØ li·ªáu c≈©\n",
    "for field in data_clean.dtype.names:\n",
    "    data_enhanced[field] = data_clean[field]\n",
    "\n",
    "# Th√™m features m·ªõi\n",
    "for feature_name, feature_values in engineered_numeric_features.items():\n",
    "    data_enhanced[feature_name] = feature_values\n",
    "\n",
    "print(f\"\\nK·∫æT QU·∫¢:\")\n",
    "print(f\"Columns tr∆∞·ªõc feature engineering: {len(data_clean.dtype.names)}\")\n",
    "print(f\"Columns sau feature engineering: {len(data_enhanced.dtype.names)}\")\n",
    "print(f\"S·ªë features m·ªõi: {len(new_fields)}\")\n",
    "\n",
    "print(f\"\\nDanh s√°ch t·∫•t c·∫£ columns hi·ªán t·∫°i:\")\n",
    "for i, col in enumerate(data_enhanced.dtype.names, 1):\n",
    "    marker = \"NEW\" if col in [field[0] for field in new_fields] else \"   \"\n",
    "    print(f\"{i:2d}. {marker} {col}\")\n",
    "\n",
    "# C·∫≠p nh·∫≠t data_clean v·ªõi data ƒë√£ c√≥ features m·ªõi\n",
    "data_clean = data_enhanced\n",
    "print(f\"\\n ƒê√£ c·∫≠p nh·∫≠t data_clean v·ªõi 3 features s·ªë m·ªõi th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5dc190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫¨P NH·∫¨T DANH S√ÅCH FEATURES\n",
      "==================================================\n",
      "NUMERIC FEATURES (bao g·ªìm 3 features m·ªõi):\n",
      " 1.     Customer_Age\n",
      " 2.     Dependent_count\n",
      " 3.     Months_on_book\n",
      " 4.     Total_Relationship_Count\n",
      " 5.     Months_Inactive_12_mon\n",
      " 6.     Contacts_Count_12_mon\n",
      " 7.     Credit_Limit\n",
      " 8.     Total_Revolving_Bal\n",
      " 9.     Avg_Open_To_Buy\n",
      "10.     Total_Amt_Chng_Q4_Q1\n",
      "11.     Total_Trans_Amt\n",
      "12.     Total_Trans_Ct\n",
      "13.     Total_Ct_Chng_Q4_Q1\n",
      "14.     Avg_Utilization_Ratio\n",
      "15. NEW Credit_Utilization_Efficiency\n",
      "16. NEW Customer_Activity_Score\n",
      "17. NEW Avg_Transaction_Amount\n",
      "\n",
      "CATEGORICAL FEATURES (kh√¥ng th√™m features m·ªõi):\n",
      " 1.     Gender\n",
      " 2.     Education_Level\n",
      " 3.     Marital_Status\n",
      " 4.     Income_Category\n",
      " 5.     Card_Category\n",
      "\n",
      "‚úÖ ƒê√£ c·∫≠p nh·∫≠t danh s√°ch features: th√™m 3 features s·ªë m·ªõi!\n",
      "   - T·ªïng numeric features: 17\n",
      "   - T·ªïng categorical features: 5\n"
     ]
    }
   ],
   "source": [
    "# C·∫≠p nh·∫≠t feature lists v·ªõi features m·ªõi\n",
    "print(\"C·∫¨P NH·∫¨T DANH S√ÅCH FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# C·∫≠p nh·∫≠t excluded columns ƒë·ªÉ lo·∫°i b·ªè ID v√† target\n",
    "excluded_columns_updated = ['CLIENTNUM', 'Attrition_Flag']\n",
    "\n",
    "# L·∫•y l·∫°i numeric v√† categorical features v·ªõi d·ªØ li·ªáu m·ªõi  \n",
    "numeric_features_updated = dp.get_numeric_columns(data_clean, exclude_columns=excluded_columns_updated)\n",
    "categorical_features_updated = dp.get_categorical_columns(data_clean)\n",
    "categorical_features_updated = [col for col in categorical_features_updated if col not in excluded_columns_updated]\n",
    "\n",
    "print(\"NUMERIC FEATURES (bao g·ªìm 3 features m·ªõi):\")\n",
    "new_numeric_features = ['Credit_Utilization_Efficiency', 'Customer_Activity_Score', 'Avg_Transaction_Amount']\n",
    "for i, col in enumerate(numeric_features_updated, 1):\n",
    "    marker = \"NEW\" if col in new_numeric_features else \"   \"\n",
    "    print(f\"{i:2d}. {marker} {col}\")\n",
    "\n",
    "print(f\"\\nCATEGORICAL FEATURES (kh√¥ng th√™m features m·ªõi):\")  \n",
    "for i, col in enumerate(categorical_features_updated, 1):\n",
    "    print(f\"{i:2d}.     {col}\")\n",
    "\n",
    "# C·∫≠p nh·∫≠t bi·∫øn ƒë·ªÉ s·ª≠ d·ª•ng ·ªü c√°c b∆∞·ªõc ti·∫øp theo\n",
    "numeric_features = numeric_features_updated  \n",
    "categorical_features = categorical_features_updated\n",
    "\n",
    "print(f\"\\n‚úÖ ƒê√£ c·∫≠p nh·∫≠t danh s√°ch features: th√™m 3 features s·ªë m·ªõi!\")\n",
    "print(f\"   - T·ªïng numeric features: {len(numeric_features)}\")\n",
    "print(f\"   - T·ªïng categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f4f95",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5ff13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th√¥ng tin numeric features:\n",
      "==================================================\n",
      "Customer_Age:\n",
      "  - Min: 26.00\n",
      "  - Max: 73.00\n",
      "  - Mean: 46.33\n",
      "  - Std: 8.02\n",
      "\n",
      "Dependent_count:\n",
      "  - Min: 0.00\n",
      "  - Max: 5.00\n",
      "  - Mean: 2.35\n",
      "  - Std: 1.30\n",
      "\n",
      "Months_on_book:\n",
      "  - Min: 13.00\n",
      "  - Max: 56.00\n",
      "  - Mean: 35.93\n",
      "  - Std: 7.99\n",
      "\n",
      "Total_Relationship_Count:\n",
      "  - Min: 1.00\n",
      "  - Max: 6.00\n",
      "  - Mean: 3.81\n",
      "  - Std: 1.55\n",
      "\n",
      "Months_Inactive_12_mon:\n",
      "  - Min: 0.00\n",
      "  - Max: 6.00\n",
      "  - Mean: 2.34\n",
      "  - Std: 1.01\n",
      "\n",
      "Contacts_Count_12_mon:\n",
      "  - Min: 0.00\n",
      "  - Max: 6.00\n",
      "  - Mean: 2.46\n",
      "  - Std: 1.11\n",
      "\n",
      "Credit_Limit:\n",
      "  - Min: 1438.30\n",
      "  - Max: 34516.00\n",
      "  - Mean: 8631.95\n",
      "  - Std: 9088.33\n",
      "\n",
      "Total_Revolving_Bal:\n",
      "  - Min: 0.00\n",
      "  - Max: 2517.00\n",
      "  - Mean: 1162.81\n",
      "  - Std: 814.95\n",
      "\n",
      "Avg_Open_To_Buy:\n",
      "  - Min: 3.00\n",
      "  - Max: 34516.00\n",
      "  - Mean: 7469.14\n",
      "  - Std: 9090.24\n",
      "\n",
      "Total_Amt_Chng_Q4_Q1:\n",
      "  - Min: 0.00\n",
      "  - Max: 3.40\n",
      "  - Mean: 0.76\n",
      "  - Std: 0.22\n",
      "\n",
      "Total_Trans_Amt:\n",
      "  - Min: 510.00\n",
      "  - Max: 18484.00\n",
      "  - Mean: 4404.09\n",
      "  - Std: 3396.96\n",
      "\n",
      "Total_Trans_Ct:\n",
      "  - Min: 10.00\n",
      "  - Max: 139.00\n",
      "  - Mean: 64.86\n",
      "  - Std: 23.47\n",
      "\n",
      "Total_Ct_Chng_Q4_Q1:\n",
      "  - Min: 0.00\n",
      "  - Max: 3.71\n",
      "  - Mean: 0.71\n",
      "  - Std: 0.24\n",
      "\n",
      "Avg_Utilization_Ratio:\n",
      "  - Min: 0.00\n",
      "  - Max: 1.00\n",
      "  - Mean: 0.27\n",
      "  - Std: 0.28\n",
      "\n",
      "Credit_Utilization_Efficiency:\n",
      "  - Min: 1.00\n",
      "  - Max: 34516.00\n",
      "  - Mean: 1965.92\n",
      "  - Std: 5567.74\n",
      "\n",
      "Customer_Activity_Score:\n",
      "  - Min: 98.15\n",
      "  - Max: 143891.00\n",
      "  - Mean: 10109.92\n",
      "  - Std: 12774.10\n",
      "\n",
      "Avg_Transaction_Amount:\n",
      "  - Min: 19.14\n",
      "  - Max: 190.19\n",
      "  - Mean: 62.61\n",
      "  - Std: 26.40\n",
      "\n",
      "Shape c·ªßa ma tr·∫≠n numeric: (10127, 17)\n",
      "\n",
      "Sau khi standardization:\n",
      "Mean c·ªßa t·ª´ng feature: [-1.50475399e-15  5.73315574e-15 -8.42265375e-16 -7.01393016e-15\n",
      " -1.01932879e-15 -1.25478114e-15  1.29575179e-14  7.96560627e-16\n",
      "  1.17493076e-14 -1.26120711e-14 -4.19049718e-16  1.23694982e-14\n",
      "  4.43291652e-15 -2.04564101e-16 -2.67874331e-15 -2.96650014e-15\n",
      " -7.55078828e-15]\n",
      "Std c·ªßa t·ª´ng feature: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Features c√≥ std = 0: 0\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o ma tr·∫≠n numeric features\n",
    "X_numeric = np.column_stack([data_clean[col] for col in numeric_features])\n",
    "\n",
    "print(\"Th√¥ng tin numeric features:\")\n",
    "print(\"=\" * 50)\n",
    "for i, col in enumerate(numeric_features):\n",
    "    values = X_numeric[:, i]\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  - Min: {np.min(values):.2f}\")\n",
    "    print(f\"  - Max: {np.max(values):.2f}\")\n",
    "    print(f\"  - Mean: {np.mean(values):.2f}\")\n",
    "    print(f\"  - Std: {np.std(values):.2f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Shape c·ªßa ma tr·∫≠n numeric: {X_numeric.shape}\")\n",
    "\n",
    "# S·ª≠ d·ª•ng h√†m standardize_features_with_info t·ª´ module\n",
    "X_numeric_scaled, standardization_info = dp.standardize_features_with_info(X_numeric)\n",
    "\n",
    "print(\"\\nSau khi standardization:\")\n",
    "print(f\"Mean c·ªßa t·ª´ng feature: {standardization_info['mean_of_standardized']}\")\n",
    "print(f\"Std c·ªßa t·ª´ng feature: {standardization_info['std_of_standardized']}\")\n",
    "print(f\"Features c√≥ std = 0: {standardization_info['features_with_zero_std']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fb1e7",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Categorical Features (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5bacc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE-HOT ENCODING CHI TI·∫æT:\n",
      "----------------------------------------\n",
      "\n",
      "Gender:\n",
      "  Unique values (2): ['F', 'M']\n",
      "  Features t·∫°o ra: 2\n",
      "\n",
      "Education_Level:\n",
      "  Unique values (6): ['College', 'Doctorate', 'Graduate', 'High School', 'Post-Graduate', 'Uneducated']\n",
      "  Features t·∫°o ra: 6\n",
      "\n",
      "Marital_Status:\n",
      "  Unique values (3): ['Divorced', 'Married', 'Single']\n",
      "  Features t·∫°o ra: 3\n",
      "\n",
      "Income_Category:\n",
      "  Unique values (5): ['$120K +', '$40K - $60K', '$60K - $80K', '$80K - $120K', 'Less than $40K']\n",
      "  Features t·∫°o ra: 5\n",
      "\n",
      "Card_Category:\n",
      "  Unique values (4): ['Blue', 'Gold', 'Platinum', 'Silver']\n",
      "  Features t·∫°o ra: 4\n",
      "\n",
      "============================================================\n",
      "T·ªîNG K·∫æT ONE-HOT ENCODING:\n",
      "- S·ªë categorical features g·ªëc: 5\n",
      "- S·ªë features sau encoding: 20\n",
      "- Shape ma tr·∫≠n categorical: (10127, 20)\n"
     ]
    }
   ],
   "source": [
    "# S·ª≠ d·ª•ng h√†m one_hot_encode_with_info t·ª´ module\n",
    "X_categorical, categorical_feature_names, encoding_detailed_info = dp.one_hot_encode_with_info(data_clean, categorical_features)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"T·ªîNG K·∫æT ONE-HOT ENCODING:\")\n",
    "print(f\"- S·ªë categorical features g·ªëc: {len(categorical_features)}\")\n",
    "print(f\"- S·ªë features sau encoding: {len(categorical_feature_names)}\")\n",
    "print(f\"- Shape ma tr·∫≠n categorical: {X_categorical.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bea27",
   "metadata": {},
   "source": [
    "## 6. T·∫°o Final Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "094401ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE MATRIX CU·ªêI C√ôNG CHO LOGISTIC REGRESSION:\n",
      "============================================================\n",
      "Shape c·ªßa X: (10127, 37)\n",
      "Shape c·ªßa y: (10127,)\n",
      "S·ªë features: 37\n",
      "S·ªë samples: 10127\n",
      "\n",
      "C·∫•u tr√∫c features:\n",
      "- Numeric features (ƒë√£ chu·∫©n h√≥a): 17\n",
      "- One-hot encoded features: 20\n",
      "\n",
      "C√≥ missing values: Kh√¥ng\n"
     ]
    }
   ],
   "source": [
    "# K·∫øt h·ª£p numeric v√† categorical features\n",
    "X_final = np.column_stack([X_numeric_scaled, X_categorical])\n",
    "\n",
    "# T·∫°o danh s√°ch t√™n features cu·ªëi c√πng\n",
    "final_feature_names = numeric_features + categorical_feature_names\n",
    "\n",
    "print(\"FEATURE MATRIX CU·ªêI C√ôNG CHO LOGISTIC REGRESSION:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape c·ªßa X: {X_final.shape}\")\n",
    "print(f\"Shape c·ªßa y: {target_binary.shape}\")\n",
    "print(f\"S·ªë features: {len(final_feature_names)}\")\n",
    "print(f\"S·ªë samples: {len(target_binary)}\")\n",
    "\n",
    "print(f\"\\nC·∫•u tr√∫c features:\")\n",
    "print(f\"- Numeric features (ƒë√£ chu·∫©n h√≥a): {len(numeric_features)}\")\n",
    "print(f\"- One-hot encoded features: {len(categorical_feature_names)}\")\n",
    "\n",
    "# Ki·ªÉm tra missing values\n",
    "has_nan = np.isnan(X_final).any()\n",
    "print(f\"\\nC√≥ missing values: {'C√≥' if has_nan else 'Kh√¥ng'}\")\n",
    "\n",
    "if has_nan:\n",
    "    nan_count = np.isnan(X_final).sum()\n",
    "    print(f\"T·ªïng s·ªë missing values: {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b1918",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf34108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN-TEST SPLIT HO√ÄN T·∫§T:\n",
      "==================================================\n",
      "Training set:\n",
      "  - Shape: (8102, 37)\n",
      "  - Class 0: 6,800 (83.9%)\n",
      "  - Class 1: 1,302 (16.1%)\n",
      "\n",
      "Test set:\n",
      "  - Shape: (2025, 37)\n",
      "  - Class 0: 1,700 (84.0%)\n",
      "  - Class 1: 325 (16.0%)\n",
      "\n",
      "T·ª∑ l·ªá train/test: 80.0% / 20.0%\n"
     ]
    }
   ],
   "source": [
    "# S·ª≠ d·ª•ng h√†m train_test_split_stratified t·ª´ module\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = dp.train_test_split_stratified(\n",
    "    X_final, target_binary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"TRAIN-TEST SPLIT HO√ÄN T·∫§T:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training set:\")\n",
    "print(f\"  - Shape: {X_train.shape}\")\n",
    "print(f\"  - Class 0: {np.sum(y_train == 0):,} ({np.sum(y_train == 0)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  - Class 1: {np.sum(y_train == 1):,} ({np.sum(y_train == 1)/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  - Shape: {X_test.shape}\")\n",
    "print(f\"  - Class 0: {np.sum(y_test == 0):,} ({np.sum(y_test == 0)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  - Class 1: {np.sum(y_test == 1):,} ({np.sum(y_test == 1)/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nT·ª∑ l·ªá train/test: {len(y_train)/len(target_binary)*100:.1f}% / {len(y_test)/len(target_binary)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115151b",
   "metadata": {},
   "source": [
    "## 8. L∆∞u d·ªØ li·ªáu ƒë√£ preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a10dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªÆ LI·ªÜU ƒê√É ƒê∆Ø·ª¢C L∆ØU TH√ÄNH C√îNG!\n",
      "==================================================\n",
      "Th∆∞ m·ª•c: /home/xv6/Lab 2/Credit Card Customer Analysis/data/processed\n",
      "C√°c files ƒë√£ t·∫°o:\n",
      "- X_train.npy: Training features\n",
      "- y_train.npy: Training labels\n",
      "- X_test.npy: Test features\n",
      "- y_test.npy: Test labels\n",
      "- feature_names.txt: T√™n c√°c features\n",
      "- preprocessing_info.txt: Th√¥ng tin preprocessing\n",
      "\n",
      "D·ªØ li·ªáu s·∫µn s√†ng cho Logistic Regression!\n"
     ]
    }
   ],
   "source": [
    "# L∆∞u d·ªØ li·ªáu ƒë√£ preprocessing\n",
    "processed_data_dir = \"/home/xv6/Lab 2/Credit Card Customer Analysis/data/processed\"\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "import os\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "# L∆∞u training data\n",
    "np.save(f\"{processed_data_dir}/X_train.npy\", X_train)\n",
    "np.save(f\"{processed_data_dir}/y_train.npy\", y_train)\n",
    "\n",
    "# L∆∞u test data\n",
    "np.save(f\"{processed_data_dir}/X_test.npy\", X_test)\n",
    "np.save(f\"{processed_data_dir}/y_test.npy\", y_test)\n",
    "\n",
    "# L∆∞u feature names\n",
    "with open(f\"{processed_data_dir}/feature_names.txt\", \"w\") as f:\n",
    "    for name in final_feature_names:\n",
    "        f.write(f\"{name}\\n\")\n",
    "\n",
    "# L∆∞u preprocessing info\n",
    "preprocessing_info = {\n",
    "    'numeric_features': numeric_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'feature_names': final_feature_names,\n",
    "    'train_size': len(y_train),\n",
    "    'test_size': len(y_test),\n",
    "    'n_features': X_train.shape[1]\n",
    "}\n",
    "\n",
    "# L∆∞u preprocessing info as text file (v√¨ kh√¥ng c√≥ json)\n",
    "with open(f\"{processed_data_dir}/preprocessing_info.txt\", \"w\") as f:\n",
    "    f.write(\"PREPROCESSING INFORMATION\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"Train size: {preprocessing_info['train_size']}\\n\")\n",
    "    f.write(f\"Test size: {preprocessing_info['test_size']}\\n\")\n",
    "    f.write(f\"Number of features: {preprocessing_info['n_features']}\\n\")\n",
    "    f.write(f\"Number of numeric features: {len(numeric_features)}\\n\")\n",
    "    f.write(f\"Number of categorical features: {len(categorical_features)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"NUMERIC FEATURES:\\n\")\n",
    "    for feat in numeric_features:\n",
    "        f.write(f\"- {feat}\\n\")\n",
    "    \n",
    "    f.write(\"\\nCATEGORICAL FEATURES:\\n\")\n",
    "    for feat in categorical_features:\n",
    "        f.write(f\"- {feat}\\n\")\n",
    "\n",
    "print(\"D·ªÆ LI·ªÜU ƒê√É ƒê∆Ø·ª¢C L∆ØU TH√ÄNH C√îNG!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Th∆∞ m·ª•c: {processed_data_dir}\")\n",
    "print(\"C√°c files ƒë√£ t·∫°o:\")\n",
    "print(\"- X_train.npy: Training features\")\n",
    "print(\"- y_train.npy: Training labels\") \n",
    "print(\"- X_test.npy: Test features\")\n",
    "print(\"- y_test.npy: Test labels\")\n",
    "print(\"- feature_names.txt: T√™n c√°c features\")\n",
    "print(\"- preprocessing_info.txt: Th√¥ng tin preprocessing\")\n",
    "\n",
    "print(f\"\\nD·ªØ li·ªáu s·∫µn s√†ng cho Logistic Regression!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796bfc2",
   "metadata": {},
   "source": [
    "## 9. T√≥m t·∫Øt Preprocessing\n",
    "\n",
    "### C√°c b∆∞·ªõc ƒë√£ th·ª±c hi·ªán:\n",
    "\n",
    "1. **Load d·ªØ li·ªáu** t·ª´ CSV v√† lo·∫°i b·ªè 2 c·ªôt cu·ªëi kh√¥ng c·∫ßn thi·∫øt\n",
    "2. **T·∫°o target binary** (0: Existing Customer, 1: Attrited Customer)\n",
    "3. **Feature selection** - lo·∫°i b·ªè ID v√† target columns\n",
    "4. **Numeric features preprocessing**:\n",
    "   - Standardization (Z-score normalization)\n",
    "   - T·∫•t c·∫£ numeric features c√≥ mean=0, std=1\n",
    "5. **Categorical features preprocessing**:\n",
    "   - One-Hot Encoding cho t·∫•t c·∫£ categorical variables\n",
    "   - X·ª≠ l√Ω ƒë√∫ng ƒë·ªãnh d·∫°ng bytes\n",
    "6. **Feature matrix creation**:\n",
    "   - K·∫øt h·ª£p numeric v√† categorical features\n",
    "   - Ki·ªÉm tra missing values\n",
    "7. **Train-Test Split**:\n",
    "   - Stratified sampling ƒë·ªÉ gi·ªØ t·ª∑ l·ªá class\n",
    "   - 80% train, 20% test\n",
    "8. **L∆∞u tr·ªØ d·ªØ li·ªáu** ƒë√£ preprocessing ƒë·ªÉ s·ª≠ d·ª•ng cho modeling\n",
    "\n",
    "### K·∫øt qu·∫£ cu·ªëi c√πng:\n",
    "- **Training set**: ~8,101 samples\n",
    "- **Test set**: ~2,025 samples\n",
    "- **Class balance**: ƒê∆∞·ª£c gi·ªØ nguy√™n trong c·∫£ train v√† test set\n",
    "- **Features**: ƒê√£ ƒë∆∞·ª£c chu·∫©n h√≥a v√† encoded ph√π h·ª£p cho Logistic Regression\n",
    "\n",
    "### S·∫µn s√†ng cho Logistic Regression Model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
